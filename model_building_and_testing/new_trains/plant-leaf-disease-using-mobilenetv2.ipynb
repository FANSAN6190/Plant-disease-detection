{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6910002,"sourceType":"datasetVersion","datasetId":3968462}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Plant Leaf Disease Detection Model Training**","metadata":{}},{"cell_type":"markdown","source":"### Step1: Importing Neccesary Libraries","metadata":{}},{"cell_type":"code","source":"import os, gc\nimport cv2, PIL\n\nimport tensorflow as tf\nfrom tensorflow import keras \nfrom tensorflow.keras import layers\nfrom tensorflow.keras import optimizers\nfrom keras import models\nfrom keras.applications import MobileNetV2\n\nfrom keras.callbacks import EarlyStopping\nimport matplotlib.pyplot as plt\nimport shutil","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-26T16:35:25.593573Z","iopub.execute_input":"2023-11-26T16:35:25.594475Z","iopub.status.idle":"2023-11-26T16:35:25.600161Z","shell.execute_reply.started":"2023-11-26T16:35:25.594439Z","shell.execute_reply":"2023-11-26T16:35:25.599155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step2: Defining Model Training Class","metadata":{}},{"cell_type":"code","source":"class ModelTrain:\n    es=EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=7,restore_best_weights=True,start_from_epoch=3)\n    main_dir=\"\"\n    def __init__(self,main_dir):\n        self.main_dir=main_dir\n        \n    ## ImageDataGenerator to apply Data Augmentation\n    def imgDataGen(self,rotation=0,zoom=1,hflip=False,vflip=False):\n        train_datagen = keras.preprocessing.image.ImageDataGenerator(\n            rescale=1./255,\n            rotation_range=rotation,\n            width_shift_range=0.2,\n            height_shift_range=0.2,\n            shear_range=0.15,\n            zoom_range=zoom,\n            horizontal_flip=hflip,\n            vertical_flip=vflip,\n            fill_mode='nearest',    \n        )\n        test_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n        valid_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n        return train_datagen,test_datagen,valid_datagen\n    \n    ## Loading images from the Directory structure\n    def flowImgData(self,folder,datagen,image_shape=(224,224),class_mode='sparse'):\n        generator = datagen.flow_from_directory(\n            os.path.join(self.main_dir,folder),\n            target_size=image_shape,\n            batch_size=32,\n            class_mode=class_mode,\n            shuffle=True\n        )\n        print(\"Generator Class Indices : \",generator.class_indices)\n        print(\"Number of Classes : \",len(generator.class_indices))\n        return generator\n    \n    ## Model Training based on given Parameters\n    def trainModel(self,crop_name,train_generator,valid_generator,model,cw,save_path=\"\",epoch=50,early_stoping=es):     \n        history = model.fit(\n              train_generator,\n              steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n              epochs=epoch,\n              validation_data=valid_generator,\n              validation_steps=valid_generator.samples/valid_generator.batch_size,\n              verbose=1,\n            class_weight=cw,\n            callbacks=[self.es],\n        )\n\n        if(save_path!=\"\"):\n            model.save(save_path)\n            shutil.make_archive(crop_name+\"_mobileNet5\",'zip', save_path)\n        return history,model\n    \n    ## Model Performace Visualization\n    def plotHistory(self,history,crop):\n        acc = history.history['accuracy']\n        val_acc = history.history['val_accuracy']\n        loss = history.history['loss']\n        val_loss = history.history['val_loss']\n        epochs = range(len(acc))\n        plt.plot(epochs, acc, 'r', label='Training accuracy')\n        plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n        plt.title(f'{crop}: Training and validation accuracy')\n        plt.legend(loc=0)\n        plt.figure()\n        plt.show()\n        plt.savefig(f\"/kaggle/working/models/{crop}_acc_vs_val_acc.png\")\n        plt.plot(epochs, loss, 'r', label='Training Loss')\n        plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n        plt.title(f'{crop}: Training and validation loss')\n        plt.legend(loc=0)\n        plt.figure()\n        plt.show()\n        plt.savefig(f\"/kaggle/working/models/{crop}_loss_vs_val_loss.png\")\n    \n    ## Predicting Image Class\n    def predict(self,model,img_path,image_shape=(224,224)):\n        img = keras.preprocessing.image.load_img(\n            img_path, target_size=image_shape\n        )\n        img_array = keras.preprocessing.image.img_to_array(img)\n        img_array = tf.expand_dims(img_array, 0)\n        predictions = model.predict(img_array)\n        score = tf.nn.softmax(predictions[0])\n        confidence=np.argmax(score)\n        return predictions,confidence\n    \n    ## Performance on test Data\n    def testAccuracy(self,test_generator,model):\n        test_loss, test_acc = model.evaluate(test_generator, verbose=2)\n        print(\"Test Accuracy : \",test_acc)\n        return test_acc\n    \n    def predictAll(self,model,dir):\n        predictionArray=[]\n        confidenceArray=[]\n        for i in os.listdir(dir):\n            img_path=os.path.join(dir,i)\n            pred,confidence=self.predict(model,img_path)\n            predictionArray.append(pred)\n            confidenceArray.append(confidence)\n            print(\"Prediction : \",pred)\n            print(\"Confidence : \",confidence)\n            print(\"Image Path : \",img_path)\n            print(\"Class : \",i)\n            print(\"--------------------------------------------------------\")\n        predictionArray=np.array(predictionArray)\n        confidenceArray=np.array(confidenceArray)\n        return predictionArray,confidenceArray\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-26T16:35:25.659935Z","iopub.execute_input":"2023-11-26T16:35:25.660855Z","iopub.status.idle":"2023-11-26T16:35:25.685286Z","shell.execute_reply.started":"2023-11-26T16:35:25.660821Z","shell.execute_reply":"2023-11-26T16:35:25.684183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndata_dir=\"/kaggle/input/individual-crop-leaf-disease-dataset/Individual_crop_leaf_disease_data/\"\ncrop_count=0;\nhistory_list=[]\nmodel_list=[]\nfor i in sorted(os.listdir(data_dir))[0:1]:\n    print(\"---------------------------------------------\")\n    print(\"Crop Name : \",i)\n    print(\"---------------------------------------------\")\n    main_dir=os.path.join(data_dir,i)\n    print(\"Directory : \",main_dir)\n    print(\"---------------------------------------------\")\n    modelTrain=ModelTrain(main_dir)\n    \n    train_datagen,test_datagen,valid_datagen=modelTrain.imgDataGen(rotation=20,zoom=0.15,hflip=True,vflip=True)\n\n    train_generator=modelTrain.flowImgData(\"train\",train_datagen)\n    test_generator=modelTrain.flowImgData(\"test\",test_datagen)\n    valid_generator=modelTrain.flowImgData(\"val\",valid_datagen)\n    \n    num_classes=len(train_generator.class_indices)\n#####################################\n    base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n    head_model = base_model.output\n    head_model = layers.AveragePooling2D(pool_size=(7, 7))(head_model)\n    head_model = layers.Flatten(name=\"flatten\")(head_model)\n    head_model = layers.Dense(1024, activation=\"relu\")(head_model)\n    head_model = layers.Dropout(0.5)(head_model)\n    head_model = layers.Dense(1024, activation=\"relu\")(head_model)\n    head_model = layers.Dropout(0.3)(head_model)\n    head_model = layers.Dense(512, activation=\"relu\")(head_model)\n    head_model = layers.Dropout(0.2)(head_model)\n    head_model = layers.Dense(256, activation=\"relu\")(head_model)\n    head_model = layers.Dropout(0.1)(head_model)\n    head_model = layers.Dense(num_classes, activation=\"softmax\")(head_model)\n    model = models.Model(inputs=base_model.input, outputs=head_model)\n    \n    for layer in base_model.layers:\n        layer.trainable = False\n#####################################\n    from sklearn.utils import class_weight\n    class_weights = class_weight.compute_sample_weight(\n        'balanced',\n        train_generator.classes)\n    class_weight_dict = dict(enumerate(class_weights))\n    \n    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizers.Adam(), metrics=[\"accuracy\"])\n    history=\"helo\"\n    history,model=modelTrain.trainModel(i,train_generator,valid_generator,model=model,save_path=os.path.join(\"/kaggle/working/models\",f\"{i}_mobileNet.pb\"),cw=class_weight_dict)\n    history_list.append(history)\n    model_list.append(model)\n\n    modelTrain.plotHistory(history,i)\n    modelTrain.testAccuracy(test_generator,model)\n    gc.collect()\n    shutil.make_archive(\"models_compressed\",'zip',\"/kaggle/working/models\")\n    \n    crop_count+=1\n    print(\"--------------------------------------------------------\")\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-26T17:40:24.630980Z","iopub.execute_input":"2023-11-26T17:40:24.631396Z","iopub.status.idle":"2023-11-26T17:49:06.198914Z","shell.execute_reply.started":"2023-11-26T17:40:24.631366Z","shell.execute_reply":"2023-11-26T17:49:06.197889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\nwith open('/kaggle/working/history.txt', 'wb') as h:\n    pickle.dump(history_list, h)\nwith open('/kaggle/working/models.txt', 'wb') as m:\n    pickle.dump(model_list, m)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T16:35:30.412958Z","iopub.status.idle":"2023-11-26T16:35:30.413412Z","shell.execute_reply.started":"2023-11-26T16:35:30.413191Z","shell.execute_reply":"2023-11-26T16:35:30.413214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(test_generator)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T18:26:15.893213Z","iopub.execute_input":"2023-11-26T18:26:15.894101Z","iopub.status.idle":"2023-11-26T18:26:16.763372Z","shell.execute_reply.started":"2023-11-26T18:26:15.894069Z","shell.execute_reply":"2023-11-26T18:26:16.762441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-26T19:40:17.954617Z","iopub.execute_input":"2023-11-26T19:40:17.955000Z","iopub.status.idle":"2023-11-26T19:40:18.360169Z","shell.execute_reply.started":"2023-11-26T19:40:17.954971Z","shell.execute_reply":"2023-11-26T19:40:18.359305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils.vis_utils import plot_model\nplot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T20:01:04.243878Z","iopub.execute_input":"2023-11-26T20:01:04.244600Z","iopub.status.idle":"2023-11-26T20:01:06.443788Z","shell.execute_reply.started":"2023-11-26T20:01:04.244563Z","shell.execute_reply":"2023-11-26T20:01:06.442333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}